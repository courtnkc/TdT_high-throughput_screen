'''
This script was used to generate Figure 1d and Figure S1. It generates a table describing the composition of residues for TdT mutants inside the user-specified bin of A/T biases.
To generate correctly-formatted input data for this script, you must first run the script "HT_assay-5 - Fig1c, Fig1d, Fig2, Fig3b, FigS1, FigS2b-d, FigS3, TablesS1-S4 - analyze_variants_in_massive_pooled_assay.py"
'''

import pandas as pd

##### USER INPUTS #####

min_bias_in_bin = 0 #minimum %A/T in the bias bin of interest
max_bias_in_bin = 1 #maximum %A/T in the bias bin of interest

activity_cutoff = 0 #minimum allowable insertion fraction (ins / [ins+del]) required for a library member to be factored into the A/T bias bin
min_n_reads = 447 #minimum number of reads required for a library member to be factored into the A/T bias bin

positions_of_NNKs = [0,1,2] #within the string of residues describing the NNK target sites, which positions are NNKs? For library 1: 0,1,2. For library 2: 0,2,3. For library 3: 0,3,7
sample_name = 'all021' #this defines the input file name. For library 1: "all021", for library 2: "all_022", for library 3: "all_023"

##### END OF USER INPUTS #####



sample_file = open('aligned_all_TdT_reads_PassedFilter_Gs_{}.txt_DATAFRAME_NNKs_lengths_GROUPED.csv'.format(sample_name),'r').read().splitlines() #opening the file generated by "HT_assay-5 - Fig1c, Fig1d, Fig2, Fig3b, FigS1, FigS2b-d, FigS3, TablesS1-S4 - analyze_variants_in_massive_pooled_assay.py"

list_of_NNKs = []

NNK_id = ''
counter = 0
for row in sample_file: #read the input file, make lists of all NNKs that belong within the bin of biases
    if counter == 0: #skip the header row
        counter += 1
        continue
    else:
        interpretable_row = row.split(',')

    NNK_input = interpretable_row[1]
    if NNK_input != NNK_id:
        NNK_id = NNK_input #making sure each NNK is only counted once
        AT_bias = float(interpretable_row[11]) 
        activity = float(interpretable_row[10])
        n_reads = int(interpretable_row[12])

        if AT_bias >= min_bias_in_bin and AT_bias <= max_bias_in_bin:
            if activity >= activity_cutoff and n_reads >= min_n_reads:
                list_of_NNKs.append(NNK_input)

NNKs_1st_position = ''
NNKs_2nd_position = ''
NNKs_3rd_position = ''

for mutant in list_of_NNKs: #iterate through all TdT mutants in this bias bin, store the residue identities at each position in a string (this will later be used to easily calculate the compositions of residues at each position) 
    residue_1 = str(mutant[positions_of_NNKs[0]])
    residue_2 = str(mutant[positions_of_NNKs[1]])
    residue_3 = str(mutant[positions_of_NNKs[2]])

    NNKs_1st_position += residue_1
    NNKs_2nd_position += residue_2
    NNKs_3rd_position += residue_3


list_of_AAs = ['R','K','H','G','A','V','I','L','M','F','Y','W','S','T','N','Q','D','E','C','P','*'] #20 natural amino acids + stop codon, arranged by the biochemical properties of their side chains

single_row_data = []
all_rows_data = []
for residue in list_of_AAs:
    single_row_data.append(residue)
    residue_frequency_1 = NNKs_1st_position.count(residue)/len(NNKs_1st_position)
    residue_frequency_2 = NNKs_2nd_position.count(residue)/len(NNKs_2nd_position)
    residue_frequency_3 = NNKs_3rd_position.count(residue)/len(NNKs_3rd_position)

    single_row_data.append(residue_frequency_1)
    single_row_data.append(residue_frequency_2)
    single_row_data.append(residue_frequency_3)

    all_rows_data.append(single_row_data)
    single_row_data = []

single_row_data.append('total mutants')
single_row_data.append(str(len(NNKs_1st_position)))
single_row_data.append(str(len(NNKs_2nd_position)))
single_row_data.append(str(len(NNKs_3rd_position)))
all_rows_data.append(single_row_data)
single_row_data = []

columns = ['residue', 'position 1', 'position 2', 'position 3']
complete_dataframe = pd.DataFrame(all_rows_data, columns = columns)
complete_dataframe.to_csv(sample_name + '_composition_of_residues_for_AT-bias_' + str(min_bias_in_bin) + '-' + str(max_bias_in_bin) + '_min_activity_' + str(activity_cutoff) + '_min_reads_' + str(min_n_reads) + '.csv')

tot_NNKs_in_bin = len(list_of_NNKs)
print('total n NNKs in this bin: ', tot_NNKs_in_bin)



