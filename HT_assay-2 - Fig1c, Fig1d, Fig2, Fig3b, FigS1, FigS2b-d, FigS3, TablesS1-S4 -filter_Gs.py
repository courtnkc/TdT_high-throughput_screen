'''
This script was part of the pipeline used to generate data shown in Figures 1c, 1d, 2, 3b, S1, S2b-d, and S3. It also produced the data provided in Tables S1-S4.
Its input is a fastq file containing concatenated F and R reads, generated by running "HT_assay-1 - Fig1c, Fig1d, Fig2, Fig3b, FigS1, FigS2b-d, FigS3, TablesS1-S4 -merge_Fwd_Rvs_reads.py"

For each "record" (i.e., concatenated F and R read from a given cluster), this script checks for homopolymeric stretches > 15 nt, and if they exist, throws out those records.
The output is another fastq file, with offending reads removed.
'''


import Bio
from Bio.Alphabet import generic_dna
from Bio import pairwise2
from Bio.pairwise2 import format_alignment
from Bio import Align
from Bio.Alphabet import IUPAC
from Bio import SeqIO
import numpy as np
import multiprocessing as mp
import datetime
import os
import time
import shutil
import re
import datetime

count = 0
good_count = 0
bad_count = 0
good_list = []
bad_list = []

polymers = [i*16 for i in 'GCAT']   #Makes a list with the homopolymeric sequences to be screened against
for record in SeqIO.parse("all_TdT_reads_FRmerge_20.5.22.fastq", "fastq"):   
    count += 1                 
    seqIsGood = True
    for i in polymers:          #Cycles through each of the possible homopolymers
        if i in record.seq:     #Checks if the homopolymer is present in each record
            bad_count += 1
            seqIsGood = False
            bad_list.append(record) 
            break
    if seqIsGood:
        good_count += 1
        good_list.append(record)

    if count%100000 == 0:   #Only writing the results to files every 100,000 reads in order to speed up computation time
        with open("FilterGs_REPORT.txt", "a") as report:
            report.write(f'Total reads: {count}.  Bad reads: {bad_count}.  Good reads: {good_count}. {datetime.datetime.now()}/n')
        with open("all_TdT_reads_FilteredOut_Gs.fastq", "a") as output_handle1:    #Creates/appends to the output file
            SeqIO.write(bad_list, output_handle1, "fastq")      
            bad_list = []    #Deleting the contents of the list after it's been written to a file
        with open("all_TdT_reads_PassedFilter_Gs.fastq", "a") as output_handle2:       #Creates/appends to the output file
            SeqIO.write(good_list, output_handle2, "fastq")        
            good_list = []    #Deleting the contents of the list after it's been written to a file
            

print("total n reads in the input was " + str(count))
print("total n good reads is " + str(good_count))
print("total n bad reads is " + str(bad_count))